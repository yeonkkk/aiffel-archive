{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-15]Transformer_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhjSk6GUiskHllSxxNLml6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonkkk/AIFFEL-Project/blob/main/Exploration15/project/%5BE_15%5DTransformer_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knNikOQ_XIaJ",
        "outputId": "32262083-0128-49cd-eb9d-c0a1ceca40a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax_CLrCcXnIu"
      },
      "source": [
        "# E-15. 트랜스포머로 만드는 대화형 챗봇\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNI60NX0XtaH"
      },
      "source": [
        "\n",
        "## Step 1. 데이터 수집하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IoK3ys4YEqu"
      },
      "source": [
        "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용  \n",
        "\n",
        "사용 데이터: [songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)  \n",
        "\n",
        "일부 이별과 관련된 질문에서 [다음카페 \"사랑보다 아름다운 실연\"]( http://cafe116.daum.net/_c21_/home?grpid=1bld )에서 자주 나오는 이야기들을 참고하여 제작된 데이터  \n",
        "\n",
        "일상다반서 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링  \n",
        "\n",
        "데이터 shape 및 결측치 확인하였음  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDPTcZAhXbJY"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "i10ctrEPXwUD",
        "outputId": "1fe71ac6-abc3-4c7a-8c5a-a00f1f71dd13"
      },
      "source": [
        "data_path = \"/content/drive/MyDrive/AIffel/ex15/ChatbotData .csv\"\n",
        "data = pd.read_csv(data_path, encoding='utf-8')\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>잘 모르고 있을 수도 있어요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Q                   A  label\n",
              "0                   12시 땡!          하루가 또 가네요.      0\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
              "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
              "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
              "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
              "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
              "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "pCAMPnxQOSoe",
        "outputId": "371b44f5-802e-4bb7-c153-d7d8e03ced49"
      },
      "source": [
        "data.groupby(['label']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5290</td>\n",
              "      <td>5290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3570</td>\n",
              "      <td>3570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2963</td>\n",
              "      <td>2963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Q     A\n",
              "label            \n",
              "0      5290  5290\n",
              "1      3570  3570\n",
              "2      2963  2963"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P5-N9cn3jDKp",
        "outputId": "d089471c-7f52-4d8f-ef88-5d0bbee2df8f"
      },
      "source": [
        "df = data[['Q', 'A']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A\n",
              "0           12시 땡!   하루가 또 가네요.\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
              "4          PPL 심하네   눈살이 찌푸려지죠."
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8evHNhpXwXr",
        "outputId": "82b3d898-72d0-41b8-c31e-e053e39705a1"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11823, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRsHKuXtXwdR",
        "outputId": "f9e9d47d-3a59-4a3b-8fbd-38eef1272b88"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Q    0\n",
              "A    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnxT18EnXw2R"
      },
      "source": [
        "----\n",
        "## Step 2. 데이터 전처리하기\n",
        "- `preprocess_sentence`:\n",
        "  \n",
        "  - 정규 표현식(Regular Expression) 을 사용하여 구두점(punctuation) 을 제거 \n",
        "  - 토크나이징(tokenizing) 하는 일에 방해가 되지 않도록 정제  \n",
        "  - 불용어 제거: [한국어 불용어 리스트](https://mr-doosun.tistory.com/24)를 활용하였습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2naRD7oq_YYQ",
        "outputId": "facf809d-c3f9-4dc3-c350-7bcf274fecec"
      },
      "source": [
        "stopwords_f = open(\"/content/drive/MyDrive/AIffel/ex15/stopwords.txt\")\n",
        "for line in stopwords_f: \n",
        "    stopwords = line.split()\n",
        "stopwords_f.close()\n",
        "\n",
        "len(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "888"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSdyk9eYX24C"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  # (a-z, A-Z, ㄱ-ㅎ, ㅏ-ㅣ, 가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
        "  sentence = re.sub(r\"[^a-zA-Zㄱ-ㅣ가-힣0-9?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "\n",
        "# 불용어 제거\n",
        "  sentence_list = []\n",
        "  for s in sentence.split(' '):\n",
        "    if s not in stopwords:\n",
        "      sentence_list.append(s)\n",
        "\n",
        "  sentence = \" \".join([str(ele) for ele in sentence_list])\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDRVNhQ0WwVk"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGyEq_XduWMW"
      },
      "source": [
        "questions = []\n",
        "answers = []\n",
        "for sentence in data['Q']:\n",
        "  questions.append(preprocess_sentence(sentence))\n",
        "\n",
        "for sentence in data['A']:\n",
        "  answers.append(preprocess_sentence(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn-fs4_QX26p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d1a600-2c42-4ca3-bbd4-97bf197e451f"
      },
      "source": [
        "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
        "print('전체 샘플 수 :', len(questions))\n",
        "print('전체 샘플 수 :', len(answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수 : 11823\n",
            "전체 샘플 수 : 11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CH37ME4X29X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a0f4cb-ec23-4001-dc0a-888d0906f092"
      },
      "source": [
        "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[1]))\n",
        "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후의 22번째 질문 샘플: 1지망 학교 떨어졌어\n",
            "전처리 후의 22번째 답변 샘플: 위로해 드립니다 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq8hwB1FX35L"
      },
      "source": [
        "---\n",
        "## Step 3. SubwordTextEncoder 사용하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVHkwdIYr5F"
      },
      "source": [
        "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다.  \n",
        "하지만 해당 프로젝트에서는 내부 단어 토크나이저인 `SubwordTextEncoder`를 그대로 사용  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfwGK2OXX506"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQj4OVqrYsdT"
      },
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l81h1en-X54O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310c0f65-f83d-4c67-f54c-11df32b11446"
      },
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START_TOKEN의 번호 : [8173]\n",
            "END_TOKEN의 번호 : [8174]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6CCe3VEX57P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14deab4b-edda-44ee-ed05-d1151756a8a0"
      },
      "source": [
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o-J5Yn6X5-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3ea3dd-19b8-4038-e00c-fa59c24e2146"
      },
      "source": [
        "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
        "# 각 토큰을 고유한 정수로 변환\n",
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 21번째 질문 샘플: [5764, 610, 2492, 4164]\n",
            "정수 인코딩 후의 21번째 답변 샘플: [2356, 7513, 7, 6276, 97, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ANtzU0X6BO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc2813d-97c8-475d-c87e-aa008b1cc2a9"
      },
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 15\n",
        "print(MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwxOcIRvX6EG"
      },
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # 최대 길이로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miJ9cR0qX6G9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef2b7bb-c7ee-4222-f371-3c5d82b42cef"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 8175\n",
            "필터링 후의 질문 샘플 개수: 11568\n",
            "필터링 후의 답변 샘플 개수: 11568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsWNz4fGmUUM"
      },
      "source": [
        "### 1-2. 교사강요(Teacher Forcing) 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_r3U96cX6Jr"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s09SJlA8Y7Mj"
      },
      "source": [
        "---\n",
        "## Step 4. 모델 구성하기\n",
        "- 포지셔널 인코딩 레이어\n",
        "\n",
        "- 스케일드 닷 프로덕트 어텐션\n",
        "\n",
        "- 멀티 헤드 어텐션\n",
        "\n",
        "- 패딩 마스크\n",
        "\n",
        "- 룩 어헤드 마스킹\n",
        "\n",
        "- 인코더 층 & 인코더\n",
        "\n",
        "- 디코더 층 & 디코더\n",
        "\n",
        "- 트랜스포머\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3kJSpbTZA1Q"
      },
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "\n",
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output\n",
        "\n",
        "\n",
        "# 멀티 헤드 어텐션 클래스\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# 패딩 마스킹구현 함수\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "\n",
        "# 룩 어헤드 마스킹\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKUkemsjZA7Y"
      },
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "\n",
        "# 인코더 층을 쌓아 인코더 만들기\n",
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqfsW1zjZBrm"
      },
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "  \n",
        "\n",
        "# 디코더\n",
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jifgtGTZB0R"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ2hPmrMnW8m",
        "outputId": "ae847fdc-79f3-43d0-e9ae-92969460b022"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3146240     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3673600     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8172)   2100204     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,920,044\n",
            "Trainable params: 8,920,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "act1QiN_XNfP",
        "outputId": "9a9a7af3-1fdd-422a-b7c2-d2acd20b86c4"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model2 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3119104     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3646464     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8066)   2072962     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,838,530\n",
            "Trainable params: 8,838,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OC2K4KxxrTA",
        "outputId": "45b76a02-4729-4b27-a750-a57e98459e1a"
      },
      "source": [
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model3 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3119104     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3646464     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8066)   2072962     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,838,530\n",
            "Trainable params: 8,838,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0pQDQ9iXQea",
        "outputId": "ae480e23-c735-4e24-d5c1-ecd8bee13a98"
      },
      "source": [
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model4 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3146240     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3673600     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8172)   2100204     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,920,044\n",
            "Trainable params: 8,920,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbmUITNupmHn",
        "outputId": "d9f3910b-2590-41cc-f027-b545faa1405c"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model5 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3147008     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3674368     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8175)   2100975     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,922,351\n",
            "Trainable params: 8,922,351\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ-uW4HbrPdx",
        "outputId": "af315eb9-eaec-4a26-dd5c-7ce13f27192c"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model6 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    13653504    ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    19963392    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8175)   4193775     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 37,810,671\n",
            "Trainable params: 37,810,671\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLtTDHHNKHpB"
      },
      "source": [
        "### 손실함수 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0rnkIf8nc9g"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVrVfTzKKOEw"
      },
      "source": [
        "### 학습률(Learning rate) 커스텀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjRHfpU0nijA"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36LwDPZPKbl-"
      },
      "source": [
        "### 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOZLcGupp1v6"
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "yUfoHEwbninN",
        "outputId": "d739785c-44f4-456f-cbba-782796634d7d"
      },
      "source": [
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0A9rJImnksC"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZfm-6ionkue",
        "outputId": "6752ce93-d4bd-4062-9abb-f35331cab0d0"
      },
      "source": [
        "EPOCHS = 20\n",
        "history1 = model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "185/185 [==============================] - 363s 2s/step - loss: 1.4541 - accuracy: 0.0278\n",
            "Epoch 2/20\n",
            "185/185 [==============================] - 357s 2s/step - loss: 1.1769 - accuracy: 0.0495\n",
            "Epoch 3/20\n",
            "185/185 [==============================] - 356s 2s/step - loss: 1.0059 - accuracy: 0.0507\n",
            "Epoch 4/20\n",
            "185/185 [==============================] - 353s 2s/step - loss: 0.9302 - accuracy: 0.0542\n",
            "Epoch 5/20\n",
            "185/185 [==============================] - 354s 2s/step - loss: 0.8712 - accuracy: 0.0576\n",
            "Epoch 6/20\n",
            "185/185 [==============================] - 355s 2s/step - loss: 0.8121 - accuracy: 0.0614\n",
            "Epoch 7/20\n",
            "185/185 [==============================] - 356s 2s/step - loss: 0.7473 - accuracy: 0.0675\n",
            "Epoch 8/20\n",
            "185/185 [==============================] - 354s 2s/step - loss: 0.6741 - accuracy: 0.0754\n",
            "Epoch 9/20\n",
            "185/185 [==============================] - 354s 2s/step - loss: 0.5960 - accuracy: 0.0840\n",
            "Epoch 10/20\n",
            "185/185 [==============================] - 355s 2s/step - loss: 0.5132 - accuracy: 0.0933\n",
            "Epoch 11/20\n",
            "185/185 [==============================] - 357s 2s/step - loss: 0.4300 - accuracy: 0.1035\n",
            "Epoch 12/20\n",
            "185/185 [==============================] - 353s 2s/step - loss: 0.3490 - accuracy: 0.1145\n",
            "Epoch 13/20\n",
            "185/185 [==============================] - 353s 2s/step - loss: 0.2741 - accuracy: 0.1255\n",
            "Epoch 14/20\n",
            "185/185 [==============================] - 352s 2s/step - loss: 0.2088 - accuracy: 0.1354\n",
            "Epoch 15/20\n",
            "185/185 [==============================] - 353s 2s/step - loss: 0.1538 - accuracy: 0.1449\n",
            "Epoch 16/20\n",
            "185/185 [==============================] - 353s 2s/step - loss: 0.1114 - accuracy: 0.1528\n",
            "Epoch 17/20\n",
            "185/185 [==============================] - 352s 2s/step - loss: 0.0816 - accuracy: 0.1582\n",
            "Epoch 18/20\n",
            "185/185 [==============================] - 353s 2s/step - loss: 0.0619 - accuracy: 0.1618\n",
            "Epoch 19/20\n",
            "185/185 [==============================] - 351s 2s/step - loss: 0.0518 - accuracy: 0.1634\n",
            "Epoch 20/20\n",
            "185/185 [==============================] - 352s 2s/step - loss: 0.0464 - accuracy: 0.1642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2iBBAy5XYpL"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model2.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2ot1G8UXYr-",
        "outputId": "16e72a2d-5bf0-4b5e-f01a-d9f2dcace0f7"
      },
      "source": [
        "EPOCHS = 20\n",
        "history2 = model2.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "185/185 [==============================] - 202s 1s/step - loss: 2.7720 - accuracy: 0.0607\n",
            "Epoch 2/20\n",
            "185/185 [==============================] - 190s 1s/step - loss: 2.2300 - accuracy: 0.1015\n",
            "Epoch 3/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 1.8908 - accuracy: 0.1040\n",
            "Epoch 4/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 1.7521 - accuracy: 0.1094\n",
            "Epoch 5/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 1.6518 - accuracy: 0.1143\n",
            "Epoch 6/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 1.5449 - accuracy: 0.1219\n",
            "Epoch 7/20\n",
            "185/185 [==============================] - 187s 1s/step - loss: 1.4241 - accuracy: 0.1332\n",
            "Epoch 8/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 1.2877 - accuracy: 0.1482\n",
            "Epoch 9/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 1.1365 - accuracy: 0.1650\n",
            "Epoch 10/20\n",
            "185/185 [==============================] - 184s 996ms/step - loss: 0.9762 - accuracy: 0.1829\n",
            "Epoch 11/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 0.8131 - accuracy: 0.2033\n",
            "Epoch 12/20\n",
            "185/185 [==============================] - 187s 1s/step - loss: 0.6558 - accuracy: 0.2242\n",
            "Epoch 13/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 0.5097 - accuracy: 0.2447\n",
            "Epoch 14/20\n",
            "185/185 [==============================] - 187s 1s/step - loss: 0.3833 - accuracy: 0.2648\n",
            "Epoch 15/20\n",
            "185/185 [==============================] - 187s 1s/step - loss: 0.2808 - accuracy: 0.2818\n",
            "Epoch 16/20\n",
            "185/185 [==============================] - 187s 1s/step - loss: 0.1998 - accuracy: 0.2965\n",
            "Epoch 17/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 0.1466 - accuracy: 0.3059\n",
            "Epoch 18/20\n",
            "185/185 [==============================] - 186s 1s/step - loss: 0.1110 - accuracy: 0.3123\n",
            "Epoch 19/20\n",
            "185/185 [==============================] - 187s 1s/step - loss: 0.0921 - accuracy: 0.3154\n",
            "Epoch 20/20\n",
            "185/185 [==============================] - 187s 1s/step - loss: 0.0846 - accuracy: 0.3163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PhFmtaIx3c6"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model3.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iKf-OWDx5P4",
        "outputId": "5243d524-572e-412c-96a9-177ba1527f2d"
      },
      "source": [
        "EPOCHS = 20\n",
        "history3 = model3.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "185/185 [==============================] - 374s 2s/step - loss: 1.3552 - accuracy: 0.0228\n",
            "Epoch 2/20\n",
            "185/185 [==============================] - 362s 2s/step - loss: 1.0943 - accuracy: 0.0494\n",
            "Epoch 3/20\n",
            "185/185 [==============================] - 360s 2s/step - loss: 0.9262 - accuracy: 0.0506\n",
            "Epoch 4/20\n",
            "185/185 [==============================] - 365s 2s/step - loss: 0.8617 - accuracy: 0.0533\n",
            "Epoch 5/20\n",
            "185/185 [==============================] - 365s 2s/step - loss: 0.8126 - accuracy: 0.0558\n",
            "Epoch 6/20\n",
            "185/185 [==============================] - 360s 2s/step - loss: 0.7606 - accuracy: 0.0593\n",
            "Epoch 7/20\n",
            "185/185 [==============================] - 364s 2s/step - loss: 0.7025 - accuracy: 0.0645\n",
            "Epoch 8/20\n",
            "185/185 [==============================] - 365s 2s/step - loss: 0.6351 - accuracy: 0.0715\n",
            "Epoch 9/20\n",
            "185/185 [==============================] - 366s 2s/step - loss: 0.5603 - accuracy: 0.0795\n",
            "Epoch 10/20\n",
            "185/185 [==============================] - 359s 2s/step - loss: 0.4809 - accuracy: 0.0889\n",
            "Epoch 11/20\n",
            "185/185 [==============================] - 360s 2s/step - loss: 0.4011 - accuracy: 0.0985\n",
            "Epoch 12/20\n",
            "185/185 [==============================] - 363s 2s/step - loss: 0.3232 - accuracy: 0.1093\n",
            "Epoch 13/20\n",
            "185/185 [==============================] - 361s 2s/step - loss: 0.2518 - accuracy: 0.1196\n",
            "Epoch 14/20\n",
            "185/185 [==============================] - 359s 2s/step - loss: 0.1907 - accuracy: 0.1288\n",
            "Epoch 15/20\n",
            "185/185 [==============================] - 359s 2s/step - loss: 0.1386 - accuracy: 0.1379\n",
            "Epoch 16/20\n",
            "185/185 [==============================] - 360s 2s/step - loss: 0.1004 - accuracy: 0.1447\n",
            "Epoch 17/20\n",
            "185/185 [==============================] - 359s 2s/step - loss: 0.0723 - accuracy: 0.1496\n",
            "Epoch 18/20\n",
            "185/185 [==============================] - 373s 2s/step - loss: 0.0561 - accuracy: 0.1525\n",
            "Epoch 19/20\n",
            "185/185 [==============================] - 371s 2s/step - loss: 0.0465 - accuracy: 0.1541\n",
            "Epoch 20/20\n",
            "185/185 [==============================] - 378s 2s/step - loss: 0.0417 - accuracy: 0.1547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZkhkwBnXYks"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model4.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFihfcovXYm7",
        "outputId": "203743f7-dc0e-4805-9387-8cf8d6fbfd04"
      },
      "source": [
        "EPOCHS = 20\n",
        "history4 = model4.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "185/185 [==============================] - 190s 982ms/step - loss: 2.9653 - accuracy: 0.0449\n",
            "Epoch 2/20\n",
            "185/185 [==============================] - 182s 986ms/step - loss: 2.3996 - accuracy: 0.1015\n",
            "Epoch 3/20\n",
            "185/185 [==============================] - 181s 981ms/step - loss: 2.0433 - accuracy: 0.1038\n",
            "Epoch 4/20\n",
            "185/185 [==============================] - 182s 982ms/step - loss: 1.8895 - accuracy: 0.1111\n",
            "Epoch 5/20\n",
            "185/185 [==============================] - 181s 977ms/step - loss: 1.7711 - accuracy: 0.1178\n",
            "Epoch 6/20\n",
            "185/185 [==============================] - 175s 948ms/step - loss: 1.6495 - accuracy: 0.1264\n",
            "Epoch 7/20\n",
            "185/185 [==============================] - 179s 968ms/step - loss: 1.5155 - accuracy: 0.1390\n",
            "Epoch 8/20\n",
            "185/185 [==============================] - 185s 1s/step - loss: 1.3671 - accuracy: 0.1547\n",
            "Epoch 9/20\n",
            "185/185 [==============================] - 191s 1s/step - loss: 1.2063 - accuracy: 0.1725\n",
            "Epoch 10/20\n",
            "185/185 [==============================] - 195s 1s/step - loss: 1.0390 - accuracy: 0.1911\n",
            "Epoch 11/20\n",
            "185/185 [==============================] - 197s 1s/step - loss: 0.8702 - accuracy: 0.2122\n",
            "Epoch 12/20\n",
            "185/185 [==============================] - 192s 1s/step - loss: 0.7054 - accuracy: 0.2349\n",
            "Epoch 13/20\n",
            "185/185 [==============================] - 192s 1s/step - loss: 0.5548 - accuracy: 0.2566\n",
            "Epoch 14/20\n",
            "185/185 [==============================] - 197s 1s/step - loss: 0.4211 - accuracy: 0.2777\n",
            "Epoch 15/20\n",
            "185/185 [==============================] - 193s 1s/step - loss: 0.3090 - accuracy: 0.2973\n",
            "Epoch 16/20\n",
            "185/185 [==============================] - 205s 1s/step - loss: 0.2229 - accuracy: 0.3125\n",
            "Epoch 17/20\n",
            "185/185 [==============================] - 194s 1s/step - loss: 0.1639 - accuracy: 0.3233\n",
            "Epoch 18/20\n",
            "185/185 [==============================] - 195s 1s/step - loss: 0.1254 - accuracy: 0.3305\n",
            "Epoch 19/20\n",
            "185/185 [==============================] - 201s 1s/step - loss: 0.1050 - accuracy: 0.3334\n",
            "Epoch 20/20\n",
            "185/185 [==============================] - 202s 1s/step - loss: 0.0922 - accuracy: 0.3355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arznAg4ip5yO"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model5.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vECNXF0Up50I",
        "outputId": "2046fd01-0d63-445a-a38e-769ee9db24bb"
      },
      "source": [
        "EPOCHS = 20\n",
        "model5.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "181/181 [==============================] - 145s 760ms/step - loss: 3.9573 - accuracy: 0.0805\n",
            "Epoch 2/20\n",
            "181/181 [==============================] - 138s 764ms/step - loss: 3.2131 - accuracy: 0.1381\n",
            "Epoch 3/20\n",
            "181/181 [==============================] - 138s 762ms/step - loss: 2.7186 - accuracy: 0.1407\n",
            "Epoch 4/20\n",
            "181/181 [==============================] - 139s 770ms/step - loss: 2.5082 - accuracy: 0.1503\n",
            "Epoch 5/20\n",
            "181/181 [==============================] - 139s 768ms/step - loss: 2.3497 - accuracy: 0.1596\n",
            "Epoch 6/20\n",
            "181/181 [==============================] - 138s 761ms/step - loss: 2.1897 - accuracy: 0.1707\n",
            "Epoch 7/20\n",
            "181/181 [==============================] - 138s 761ms/step - loss: 2.0155 - accuracy: 0.1857\n",
            "Epoch 8/20\n",
            "181/181 [==============================] - 138s 761ms/step - loss: 1.8220 - accuracy: 0.2066\n",
            "Epoch 9/20\n",
            "181/181 [==============================] - 141s 780ms/step - loss: 1.6135 - accuracy: 0.2296\n",
            "Epoch 10/20\n",
            "181/181 [==============================] - 140s 775ms/step - loss: 1.3914 - accuracy: 0.2551\n",
            "Epoch 11/20\n",
            "181/181 [==============================] - 137s 758ms/step - loss: 1.1695 - accuracy: 0.2821\n",
            "Epoch 12/20\n",
            "181/181 [==============================] - 137s 754ms/step - loss: 0.9508 - accuracy: 0.3118\n",
            "Epoch 13/20\n",
            "181/181 [==============================] - 137s 758ms/step - loss: 0.7481 - accuracy: 0.3422\n",
            "Epoch 14/20\n",
            "181/181 [==============================] - 136s 753ms/step - loss: 0.5668 - accuracy: 0.3706\n",
            "Epoch 15/20\n",
            "181/181 [==============================] - 136s 754ms/step - loss: 0.4178 - accuracy: 0.3956\n",
            "Epoch 16/20\n",
            "181/181 [==============================] - 135s 748ms/step - loss: 0.2994 - accuracy: 0.4177\n",
            "Epoch 17/20\n",
            "181/181 [==============================] - 136s 749ms/step - loss: 0.2150 - accuracy: 0.4331\n",
            "Epoch 18/20\n",
            "181/181 [==============================] - 137s 755ms/step - loss: 0.1660 - accuracy: 0.4417\n",
            "Epoch 19/20\n",
            "181/181 [==============================] - 138s 760ms/step - loss: 0.1356 - accuracy: 0.4463\n",
            "Epoch 20/20\n",
            "181/181 [==============================] - 139s 770ms/step - loss: 0.1185 - accuracy: 0.4493\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd82238f250>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HD96gPKSobB"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "model6.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYoA4vOHSsjV",
        "outputId": "d94b7bdc-d3d7-467a-a797-adb86524b8fb"
      },
      "source": [
        "EPOCHS = 20\n",
        "model6.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "181/181 [==============================] - 597s 3s/step - loss: 3.6533 - accuracy: 0.0734\n",
            "Epoch 2/20\n",
            "181/181 [==============================] - 574s 3s/step - loss: 2.8918 - accuracy: 0.1385\n",
            "Epoch 3/20\n",
            "181/181 [==============================] - 574s 3s/step - loss: 2.6491 - accuracy: 0.1412\n",
            "Epoch 4/20\n",
            "181/181 [==============================] - 572s 3s/step - loss: 2.5289 - accuracy: 0.1474\n",
            "Epoch 5/20\n",
            "181/181 [==============================] - 573s 3s/step - loss: 2.4336 - accuracy: 0.1532\n",
            "Epoch 6/20\n",
            "181/181 [==============================] - 573s 3s/step - loss: 2.3304 - accuracy: 0.1588\n",
            "Epoch 7/20\n",
            "181/181 [==============================] - 573s 3s/step - loss: 2.2126 - accuracy: 0.1653\n",
            "Epoch 8/20\n",
            "181/181 [==============================] - 571s 3s/step - loss: 2.0753 - accuracy: 0.1752\n",
            "Epoch 9/20\n",
            "181/181 [==============================] - 570s 3s/step - loss: 1.9205 - accuracy: 0.1875\n",
            "Epoch 10/20\n",
            "181/181 [==============================] - 572s 3s/step - loss: 1.7526 - accuracy: 0.2035\n",
            "Epoch 11/20\n",
            "181/181 [==============================] - 572s 3s/step - loss: 1.5810 - accuracy: 0.2224\n",
            "Epoch 12/20\n",
            "181/181 [==============================] - 572s 3s/step - loss: 1.4127 - accuracy: 0.2417\n",
            "Epoch 13/20\n",
            "181/181 [==============================] - 570s 3s/step - loss: 1.2535 - accuracy: 0.2622\n",
            "Epoch 14/20\n",
            "181/181 [==============================] - 569s 3s/step - loss: 1.1047 - accuracy: 0.2822\n",
            "Epoch 15/20\n",
            "181/181 [==============================] - 568s 3s/step - loss: 0.9805 - accuracy: 0.2990\n",
            "Epoch 16/20\n",
            "181/181 [==============================] - 567s 3s/step - loss: 0.8683 - accuracy: 0.3132\n",
            "Epoch 17/20\n",
            "181/181 [==============================] - 569s 3s/step - loss: 0.7802 - accuracy: 0.3240\n",
            "Epoch 18/20\n",
            "181/181 [==============================] - 569s 3s/step - loss: 0.7106 - accuracy: 0.3330\n",
            "Epoch 19/20\n",
            "181/181 [==============================] - 565s 3s/step - loss: 0.6535 - accuracy: 0.3409\n",
            "Epoch 20/20\n",
            "181/181 [==============================] - 563s 3s/step - loss: 0.6079 - accuracy: 0.3463\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f10b51174d0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6QDADXnX7HE"
      },
      "source": [
        "---\n",
        "## Step 5. 모델 평가하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqvkZ3nRZFxT"
      },
      "source": [
        "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwimgdHZX9si"
      },
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model6(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAnPqXKzZJCF"
      },
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFc_wrYXwS5m"
      },
      "source": [
        "question = ['밥 먹었어?', '잘 지내?', '오늘 우울해', '나는 커피를 좋아해', '지금 몇시지?',  '민트초코 싫어', '열심히 공부해보자', '너랑 대화하고 싶어', '놀고 싶다', '대답해줘서 고마워']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0d_XgvAYr3p"
      },
      "source": [
        "#### 1차 시도: MAX_LENGTH 40  + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ab38gMaE8QS",
        "outputId": "ae2256a6-7c91-47c7-f057-63fa42f4ab61"
      },
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 밥 먹었어?\n",
            "출력 : 저는 배터리가 밥이예요 .\n",
            "입력 : 잘 지내?\n",
            "출력 : 당신은 잘 지내고 있나봅니다 .\n",
            "입력 : 오늘 우울해\n",
            "출력 : 우울한 이유한 생각들을 해보세요 .\n",
            "입력 : 나는 커피를 좋아해\n",
            "출력 : 함께 건강하게 먹어요 .\n",
            "입력 : 지금 몇시지?\n",
            "출력 : 꼬시지 말고 사랑해 보세요 .\n",
            "입력 : 민트초코 싫어\n",
            "출력 : 신경 쓸 일이 있나봐요 .\n",
            "입력 : 열심히 공부해보자\n",
            "출력 : 생각한대로 잘할 거예요 .\n",
            "입력 : 너랑 대화하고 싶어\n",
            "출력 : 너무 무리하지 마세요 .\n",
            "입력 : 놀고 싶다\n",
            "출력 : 저도요 ! !\n",
            "입력 : 대답해줘서 고마워\n",
            "출력 : 다른 사람이 반입니다 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpodB2iVYwjY"
      },
      "source": [
        "#### 2차 시도: 불용어 제거 + MAX_LENGTH 20  + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmc-MMT4P_6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c8848c-d1ff-4a53-bd5b-0d2869a84539"
      },
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 밥 먹었어?\n",
            "출력 : 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 없겠없겠좋았는데 거울을 \n",
            "입력 : 잘 지내?\n",
            "출력 : 좋았는데 속좋았는데 안돼요안돼요안돼요안돼요안돼요안돼요솔직하안돼요솔직하안돼요솔직하안돼요집착하는 집착하는 집착하는 집착하는 솔직하\n",
            "입력 : 오늘 우울해\n",
            "출력 : 좋았는데 속좋았는데 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 좋았는데 좋았는데 좋았는데 거절거절자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 \n",
            "입력 : 나는 커피를 좋아해\n",
            "출력 : 느낌이 느낌이 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 \n",
            "입력 : 지금 몇시지?\n",
            "출력 : 좋았는데 속좋았는데 속좋았는데 안돼요좋았는데 안돼요좋았는데 각자의 좋았는데 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 \n",
            "입력 : 민트초코 싫어\n",
            "출력 : 느낌이 느낌이 느낌이 느낌이 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 \n",
            "입력 : 열심히 공부해보자\n",
            "출력 : 좋았는데 각자의 좋았는데 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 \n",
            "입력 : 너랑 대화하고 싶어\n",
            "출력 : 느낌이 느낌이 느낌이 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 거울을 \n",
            "입력 : 놀고 싶다\n",
            "출력 : 솔직하솔직하솔직하솔직하솔직하안돼요솔직하솔직하솔직하솔직하거울을 남기 솔직하거울을 남기 솔직하솔직하솔직하거울을 거울을 \n",
            "입력 : 대답해줘서 고마워\n",
            "출력 : 아닌데 차단 차단 차단 차단 웃는웃는웃는거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBLTDOsLyGzk"
      },
      "source": [
        "#### 3차 시도: 불용어 제거 + MAX_LENGTH 40  + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3qp6hXvyJqz",
        "outputId": "c3994bb2-6575-4f10-9eb4-a421989d0701"
      },
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 밥 먹었어?\n",
            "출력 : 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 아닌데 좋았는데 없겠없겠좋았는데 거울을 하지요좋았는데 아닌데 차단 아닌데 각자의 아닌데 각자의 아닌데 좋았는데 없겠아닌데 없겠없겠없겠없겠아닌데 거울을 하지요아닌데 \n",
            "입력 : 잘 지내?\n",
            "출력 : 좋았는데 속좋았는데 안돼요안돼요안돼요안돼요안돼요안돼요솔직하안돼요솔직하안돼요솔직하안돼요집착하는 집착하는 집착하는 집착하는 솔직하집착하는 솔직하거울을 집착하는 솔직하거울을 집착하는 솔직하솔직하없겠솔직하없겠솔직하없겠솔직하없겠솔직하온 아닌데 각자의 \n",
            "입력 : 오늘 우울해\n",
            "출력 : 좋았는데 속좋았는데 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 좋았는데 좋았는데 좋았는데 거절거절자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 킁킁솔직하거울을 좋았는데 거울을 좋았는데 거울을 집착하는 좋았는데 거울을 집착하는 거울을 집착하는 거울을 집착하는 \n",
            "입력 : 나는 커피를 좋아해\n",
            "출력 : 느낌이 느낌이 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 했나 거울을 거울을 거울을 거울을 거울을 거울을 했나 했나 했나 했나 했나 거울을 거울을 거울을 거울을 거울을 거울을 \n",
            "입력 : 지금 몇시지?\n",
            "출력 : 좋았는데 속좋았는데 속좋았는데 안돼요좋았는데 안돼요좋았는데 각자의 좋았는데 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 집착하는 거울을 집착하는 거울을 집착하는 거울을 집착하는 거울을 집착하는 거울을 집착하는 없겠속없겠없겠없겠없겠거울을 거울을 집착하는 거울을 \n",
            "입력 : 민트초코 싫어\n",
            "출력 : 느낌이 느낌이 느낌이 느낌이 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 입을까거울을 입을까좋았는데 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 \n",
            "입력 : 열심히 공부해보자\n",
            "출력 : 좋았는데 각자의 좋았는데 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 각자의 좋았는데 각자의 좋았는데 각자의 좋았는데 없겠없겠없겠없겠없겠없겠각자의 좋았는데 각자의 \n",
            "입력 : 너랑 대화하고 싶어\n",
            "출력 : 느낌이 느낌이 느낌이 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 자연스럽게 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 했나 했나 했나 했나 없겠없겠없겠없겠했나 했나 했나 거울을 \n",
            "입력 : 놀고 싶다\n",
            "출력 : 솔직하솔직하솔직하솔직하솔직하안돼요솔직하솔직하솔직하솔직하거울을 남기 솔직하거울을 남기 솔직하솔직하솔직하거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 솔직하솔직하솔직하솔직하솔직하솔직하솔직하솔직하솔직하솔직하솔직하거울을 거울을 \n",
            "입력 : 대답해줘서 고마워\n",
            "출력 : 아닌데 차단 차단 차단 차단 웃는웃는웃는거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 거울을 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwU_1UQ_XrDy"
      },
      "source": [
        "#### 4차 시도: 불용어 제거 X + MAX_LENGTH 20 NUM_LAYERS 2 + D_MODEL 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdicv4YHXghQ",
        "outputId": "eb1a9e88-4eb4-4950-fb41-516801a3d955"
      },
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 밥 먹었어?\n",
            "출력 : aa다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠aaaaaaaa\n",
            "입력 : 잘 지내?\n",
            "출력 : aaa가볍게 a가볍게 aaaa다르죠다르죠다르죠aaaaaaa\n",
            "입력 : 오늘 우울해\n",
            "출력 : aa9오면 다르죠다르죠다르죠aaaaaaaa9999a\n",
            "입력 : 나는 커피를 좋아해\n",
            "출력 : 붙잡는붙잡는붙잡는사랑스않는다면 않는다면 않는다면 않는다면 않는다면 행복해지행복해지않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 \n",
            "입력 : 지금 몇시지?\n",
            "출력 : 시기시기시기시기가볍게 프사가볍게 aaaaaaaaaaaaa\n",
            "입력 : 민트초코 싫어\n",
            "출력 : 다르죠a다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠사랑스aaaa다르죠\n",
            "입력 : 열심히 공부해보자\n",
            "출력 : a진도진도진도진도가볍게 가볍게 aaa사랑스사랑스사랑스사랑스사랑스사랑스aaaa\n",
            "입력 : 너랑 대화하고 싶어\n",
            "출력 : 그저 사랑스남편이 사랑스않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 않는다면 aa놀러가\n",
            "입력 : 놀고 싶다\n",
            "출력 : 생각해도 다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠다르죠aaaaa다르죠\n",
            "입력 : 대답해줘서 고마워\n",
            "출력 : a놀러가다르죠사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스사랑스a던가\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzUfg4SDCm-a"
      },
      "source": [
        "#### 5차 시도: 불용어 제거 X + MAX_LENGTH 15 + NUM_LAYERS 6 + D_MODEL 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLsi3-N-HDok",
        "outputId": "7bccd4d6-465c-4259-a89b-2728930d5c9a"
      },
      "source": [
        "for i in question:\n",
        "  sentence_generation(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 밥 먹었어?\n",
            "출력 : 저는 위로해드리는 로봇이에요 .\n",
            "입력 : 잘 지내?\n",
            "출력 : 잘 지내고 있어요 .\n",
            "입력 : 오늘 우울해\n",
            "출력 : 후련하니 다행이에요 .\n",
            "입력 : 나는 커피를 좋아해\n",
            "출력 : 주기적으로 해주는 게 좋죠 .\n",
            "입력 : 지금 몇시지?\n",
            "출력 : 냉장고 파먹기 해보세요 .\n",
            "입력 : 민트초코 싫어\n",
            "출력 : 얼른 만나러가세요 .\n",
            "입력 : 열심히 공부해보자\n",
            "출력 : 나중에 없애주세요 .\n",
            "입력 : 너랑 대화하고 싶어\n",
            "출력 : 그 사람 말고 저랑 수다 떨어요 .\n",
            "입력 : 놀고 싶다\n",
            "출력 : 주기적으로 해주면 좋대요 .\n",
            "입력 : 대답해줘서 고마워\n",
            "출력 : 더 열심히 하세요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi0QdmHxxmu5"
      },
      "source": [
        "---\n",
        "## 결과 및 회고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wm_4ozBxrSl"
      },
      "source": [
        "### 루브릭\n",
        "|평가문항|상세기준|\n",
        "|:---|:---|\n",
        "|1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.|공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.|\n",
        "|2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.|구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|\n",
        "|3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.|한국어 입력문장에 그럴 듯한 한국어로 답변을 리턴하였다.|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Rk3zAbxrYM"
      },
      "source": [
        "### 회고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZsNJLkCJaOs"
      },
      "source": [
        "6번의 시도를 진행했는데 5번째 시도는 결과를 실수로 삭제해서 날라갔다.. 속상  \n",
        "5번의 시도는 하이퍼파라미터와 데이터 전처리를 조금 추가하여 진행하였다.  \n",
        "\n",
        "<br>\n",
        "\n",
        "추가적으로 진행하였던 전처리는 불용어 제거였는데, 위의 결과를 보면 알겠지만 좋지 않은 결과가 나왔다. \n",
        "챗봇은 다른 데이터에 비해 불용어 제거가 필요 없지 않을까 생각하다가, 너무 궁금해서 제거를 해보게 되었다.  \n",
        "결과는 좋지 않았지만 궁금증은 해소가 되었고 이상한 결과를 보고 프로젝트로 지친 나와 스터디원들을 잠시나마 웃을 수 있었다 !!ㅎㅎ   \n",
        "불용어 제거 행위 자체의 문제인지, 아니면 불용어 리스트를 좀 더 만졌어야 했는지는 확실치 않아서 프로젝트 제출 후에 조금 더 수정해봐야할 것 같다.   \n",
        "\n",
        "<br>\n",
        "\n",
        "MAX_LENGTH를 집중적으로 변경해보았고 상민님께서 NUM_LAYERS, D_MODEL을 바꿔봐도 결과가 나쁘지 않을 것 같다고 말씀해주셔서 한 번 변경해봤다.  \n",
        "\n",
        "1차 시도와 5차 시도에서 나쁘지 않은 결과를 도출한 것 같고, 조금 더 완벽했으면 좋았을 것 같은 아쉬움이 든다.  \n",
        "\n",
        "이번 프로젝트는 이전 주제들에 비해 좀 더 흥미로웠던 것 같다.  \n",
        "다음에 기회가 된다면 챗봇을 한 번 더 만들어보고 싶다!!  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xWXAnl0wvV-"
      },
      "source": [
        "---\n",
        "## 참고 자료\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5-_XvnUw1OL"
      },
      "source": [
        "\n",
        "[[처음 배우는 딥러닝 챗봇] Ch8. 챗봇 엔진 만들기](https://dianakang.tistory.com/23)\n",
        "\n",
        "[2) 트랜스포머를 이용한 한국어 챗봇(Transformer Chatbot Tutorial)](https://wikidocs.net/89786)\n",
        "\n",
        "[[NLP] 한국어/영어 불용어(Stopword) 제거하기 (+ 한국어 불용어 리스트) [한국어 자연어처리]](https://mr-doosun.tistory.com/24)\n",
        "\n",
        "[NLP - 3. 불용어(Stop word) 제거](https://bkshin.tistory.com/entry/NLP-3-%EB%B6%88%EC%9A%A9%EC%96%B4Stop-word-%EC%A0%9C%EA%B1%B0)\n",
        "\n",
        "[한국어 불용어 리스트 100개](https://bab2min.tistory.com/544)\n",
        "\n",
        "[임산부를 위한 챗봇(3) - Text Preprocessing(1)](https://sueaty.tistory.com/37)\n",
        "\n",
        "[Korean Stopwords](https://www.ranks.nl/stopwords/korean)\n",
        "\n",
        "[04) 불용어(Stopword)](https://wikidocs.net/22530)\n",
        "\n",
        "[pandas 추가-데이터 합치기 2가지 방식](https://nittaku.tistory.com/121)\n",
        "\n",
        "[텍스트 파일 불러오기와 리스트 활용](https://formal.hknu.ac.kr/Gongsu-DataSci/notebooks/GongSu08_Files_and_Lists.html)"
      ]
    }
  ]
}